{
    "name": "root",
    "gauges": {
        "PlayerBehaviour.Policy.Entropy.mean": {
            "value": 0.6349040865898132,
            "min": 0.5884312391281128,
            "max": 1.3299775123596191,
            "count": 181
        },
        "PlayerBehaviour.Policy.Entropy.sum": {
            "value": 6349.041015625,
            "min": 5884.3125,
            "max": 13310.4150390625,
            "count": 181
        },
        "PlayerBehaviour.Step.mean": {
            "value": 1809998.0,
            "min": 9999.0,
            "max": 1809998.0,
            "count": 181
        },
        "PlayerBehaviour.Step.sum": {
            "value": 1809998.0,
            "min": 9999.0,
            "max": 1809998.0,
            "count": 181
        },
        "PlayerBehaviour.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.12534703314304352,
            "min": 0.016979621723294258,
            "max": 0.16044805943965912,
            "count": 181
        },
        "PlayerBehaviour.Policy.ExtrinsicValueEstimate.sum": {
            "value": 250.9447479248047,
            "min": 34.078102111816406,
            "max": 320.8961181640625,
            "count": 181
        },
        "PlayerBehaviour.Environment.EpisodeLength.mean": {
            "value": 99.6,
            "min": 96.07766990291262,
            "max": 113.75294117647059,
            "count": 181
        },
        "PlayerBehaviour.Environment.EpisodeLength.sum": {
            "value": 9960.0,
            "min": 9589.0,
            "max": 10197.0,
            "count": 181
        },
        "PlayerBehaviour.LevelReached.mean": {
            "value": 1.3,
            "min": 1.1237113402061856,
            "max": 1.5445544554455446,
            "count": 181
        },
        "PlayerBehaviour.LevelReached.sum": {
            "value": 130.0,
            "min": 109.0,
            "max": 156.0,
            "count": 181
        },
        "PlayerBehaviour.Environment.CumulativeReward.mean": {
            "value": 0.3,
            "min": 0.12371134020618557,
            "max": 0.5445544554455446,
            "count": 181
        },
        "PlayerBehaviour.Environment.CumulativeReward.sum": {
            "value": 30.0,
            "min": 12.0,
            "max": 55.0,
            "count": 181
        },
        "PlayerBehaviour.Policy.ExtrinsicReward.mean": {
            "value": 0.3,
            "min": 0.12371134020618557,
            "max": 0.5445544554455446,
            "count": 181
        },
        "PlayerBehaviour.Policy.ExtrinsicReward.sum": {
            "value": 30.0,
            "min": 12.0,
            "max": 55.0,
            "count": 181
        },
        "PlayerBehaviour.Losses.PolicyLoss.mean": {
            "value": 0.13320100405209812,
            "min": 0.12010098340995683,
            "max": 0.150143389867153,
            "count": 181
        },
        "PlayerBehaviour.Losses.PolicyLoss.sum": {
            "value": 0.6660050202604906,
            "min": 0.5082491211258457,
            "max": 0.750716949335765,
            "count": 181
        },
        "PlayerBehaviour.Losses.ValueLoss.mean": {
            "value": 0.007589996067083185,
            "min": 0.004213395288778301,
            "max": 0.015313460581160926,
            "count": 181
        },
        "PlayerBehaviour.Losses.ValueLoss.sum": {
            "value": 0.037949980335415925,
            "min": 0.021066976443891505,
            "max": 0.07656730290580463,
            "count": 181
        },
        "PlayerBehaviour.Policy.LearningRate.mean": {
            "value": 0.00029945875601987345,
            "min": 0.00029945875601987345,
            "max": 0.0002999984430755174,
            "count": 181
        },
        "PlayerBehaviour.Policy.LearningRate.sum": {
            "value": 0.0014972937800993673,
            "min": 0.0011978461456157979,
            "max": 0.0014999782632072237,
            "count": 181
        },
        "PlayerBehaviour.Policy.Epsilon.mean": {
            "value": 0.1998195852798196,
            "min": 0.1998195852798196,
            "max": 0.1999994810249995,
            "count": 181
        },
        "PlayerBehaviour.Policy.Epsilon.sum": {
            "value": 0.999097926399098,
            "min": 0.7992820482992821,
            "max": 0.9999927543999929,
            "count": 181
        },
        "PlayerBehaviour.Policy.Beta.mean": {
            "value": 0.0004991159678711161,
            "min": 0.0004991159678711161,
            "max": 0.0004999974570224974,
            "count": 181
        },
        "PlayerBehaviour.Policy.Beta.sum": {
            "value": 0.0024955798393555806,
            "min": 0.001996482036666482,
            "max": 0.0024999644965599645,
            "count": 181
        },
        "PlayerBehaviour.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 181
        },
        "PlayerBehaviour.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 181
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1653901217",
        "python_version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Sean\\AppData\\Local\\Programs\\Python\\Python37\\Scripts\\mlagents-learn config/ppo/roguelike.yaml --run-id=2022-30-05_19-00-16-00",
        "mlagents_version": "0.28.0",
        "mlagents_envs_version": "0.28.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.6",
        "end_time_seconds": "1653909164"
    },
    "total": 7947.441394699999,
    "count": 1,
    "self": 0.006203099999765982,
    "children": {
        "run_training.setup": {
            "total": 0.08602379999999998,
            "count": 1,
            "self": 0.08602379999999998
        },
        "TrainerController.start_learning": {
            "total": 7947.3491678,
            "count": 1,
            "self": 5.261087899853919,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.3246055,
                    "count": 1,
                    "self": 6.3246055
                },
                "TrainerController.advance": {
                    "total": 7935.661942700146,
                    "count": 243327,
                    "self": 5.013594900452517,
                    "children": {
                        "env_step": {
                            "total": 2161.8476011999046,
                            "count": 243327,
                            "self": 1560.6563633002843,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 598.3625472997469,
                                    "count": 243327,
                                    "self": 11.719273099604834,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 586.6432742001421,
                                            "count": 226294,
                                            "self": 263.82665199980556,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 322.8166222003365,
                                                    "count": 226294,
                                                    "self": 322.8166222003365
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.828690599873431,
                                    "count": 243326,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 7874.980400299777,
                                            "count": 243326,
                                            "is_parallel": true,
                                            "self": 6624.506871199792,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0004397000000002649,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00023060000000008074,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00020910000000018414,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00020910000000018414
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1250.4730893999854,
                                                    "count": 243326,
                                                    "is_parallel": true,
                                                    "self": 22.799991099637055,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 30.860180500126052,
                                                            "count": 243326,
                                                            "is_parallel": true,
                                                            "self": 30.860180500126052
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1129.5081813001398,
                                                            "count": 243326,
                                                            "is_parallel": true,
                                                            "self": 1129.5081813001398
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 67.3047365000825,
                                                            "count": 243326,
                                                            "is_parallel": true,
                                                            "self": 40.04480469994064,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 27.25993180014186,
                                                                    "count": 486652,
                                                                    "is_parallel": true,
                                                                    "self": 27.25993180014186
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 5768.800746599789,
                            "count": 243326,
                            "self": 5.447001299758085,
                            "children": {
                                "process_trajectory": {
                                    "total": 1155.9058178000369,
                                    "count": 243326,
                                    "self": 1155.6959821000373,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.20983569999953033,
                                            "count": 3,
                                            "self": 0.20983569999953033
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 4607.447927499994,
                                    "count": 880,
                                    "self": 711.1794393999976,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 3896.2684880999964,
                                            "count": 563300,
                                            "self": 3896.2684880999964
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.10153170000012324,
                    "count": 1,
                    "self": 0.011160000000018044,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.09037170000010519,
                            "count": 1,
                            "self": 0.09037170000010519
                        }
                    }
                }
            }
        }
    }
}